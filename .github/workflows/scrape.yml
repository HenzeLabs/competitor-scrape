name: Weekly Scrape

name: Weekly Scrape

on:
  schedule:
    - cron: '0 9 * * 1'   # Mondays 09:00 UTC
  workflow_dispatch:

permissions:
  contents: read

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: playwright install --with-deps

      - name: Cache Playwright
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('requirements.txt') }}

      - name: Run scraper
        env:
          GCP_CREDENTIALS_JSON: ${{ secrets.GCP_CREDENTIALS_JSON }}
          GOOGLE_DOC_ID: ${{ secrets.GOOGLE_DOC_ID }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          python -m scraper.cli scrape --site all

      - name: Summarize & push to Google Doc
        if: always()
        env:
          GCP_CREDENTIALS_JSON: ${{ secrets.GCP_CREDENTIALS_JSON }}
          GOOGLE_DOC_ID: ${{ secrets.GOOGLE_DOC_ID }}
        run: |
          python scripts/summarize_to_gdoc.py || echo "summary step skipped (script missing or failed)"

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-results-${{ github.run_id }}
          path: |
            data/processed/
            data/diffs/
          if-no-files-found: ignore
on:
  schedule:
    - cron: '0 9 * * 1'   # Mondays 09:00 UTC
  workflow_dispatch:

permissions:
  contents: read

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: playwright install --with-deps

      - name: Cache Playwright
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('requirements.txt') }}

      - name: Run scraper
        env:
          GCP_CREDENTIALS_JSON: ${{ secrets.GCP_CREDENTIALS_JSON }}
          GOOGLE_DOC_ID: ${{ secrets.GOOGLE_DOC_ID }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          python -m scraper.cli scrape --site all

      - name: Summarize & push to Google Doc
        if: always()
        env:
          GCP_CREDENTIALS_JSON: ${{ secrets.GCP_CREDENTIALS_JSON }}
          GOOGLE_DOC_ID: ${{ secrets.GOOGLE_DOC_ID }}
        run: |
          python scripts/summarize_to_gdoc.py || echo "summary step skipped (script missing or failed)"

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-results-${{ github.run_id }}
          path: |
            data/processed/
            data/diffs/
          if-no-files-found: ignore
